{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_hello(191206).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indiegolab/nlp_class/blob/master/rnn_hello(191206).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy1ljy6XpGzo",
        "colab_type": "code",
        "outputId": "5d58af8c-4772-4b78-b3df-5f2b5ee2770e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#tensorflow 2.0 임포트\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geVw3sv7pRPL",
        "colab_type": "code",
        "outputId": "d9bed17a-0af6-4003-a33e-2ca31950c62c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Tensorflow 버전 확인\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRWnjtRVlyUJ",
        "colab_type": "code",
        "outputId": "5693b2df-0e78-4585-d5ed-66638005ab36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "idx2char = ['토', '마', '를', '먹', '자']\n",
        "\n",
        "# 토마토 가르치기 실습: 토토마를자먹 -> 토마토를먹자\n",
        "# x_data = [[0, 0, 1, 2, 4, 3]]   ## 토토마를자먹\n",
        "y_data = [[0, 1, 0, 2, 3, 4]]    # 토마토를먹자\n",
        "\n",
        "num_classes = 5\n",
        "input_dim = 5  # one-hot size, one_hot을 직접 예측하기위한 hidden_size와 동일\n",
        "sequence_length = 6  # |토마토를먹자| == 6\n",
        "learning_rate = 0.1\n",
        "\n",
        "x_one_hot = np.array([[[1, 0, 0, 0, 0],   # 토 0\n",
        "                       [1, 0, 0, 0, 0],   # 토 0\n",
        "                       [0, 1, 0, 0, 0],   # 마 1\n",
        "                       [0, 0, 1, 0, 0],   # 를 2\n",
        "                       [0, 0, 0, 0, 1],   # 자 4\n",
        "                       [0, 0, 0, 1, 0]]], # 먹 3\n",
        "                     dtype=np.float32)\n",
        "\n",
        "# 클래스 벡터(정수)를 이진 클래스 행렬로 변환합니다. \n",
        "## y : 행렬로 변환 할 클래스 벡터 (0에서 num_classes의 정수까지)\n",
        "## num_classes : 총 클래스 수.\n",
        "y_one_hot = tf.keras.utils.to_categorical(y_data, num_classes=num_classes)\n",
        "print(\"x_one_hot의 shape\", x_one_hot.shape)\n",
        "print(\"y_one_hot의 shape\", y_one_hot.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_one_hot의 shape (1, 6, 5)\n",
            "y_one_hot의 shape (1, 6, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeqRGtFD4AyM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* Sequential 모델  \n",
        "\n",
        "케라스에서는 층(layer)을 조합하여 모델(model)을 만든다. 모델은 일반적으로 층들의 그래프이다. 가장 흔한 모델 구조는 층을 차례대로 쌓은 tf.keras.Sequential 모델이다.\n",
        "\n",
        "\n",
        "레이어 생성 자체를 GRU나 LSTM로 생성할 수 도 있고, Cell만 따로 만들어서 RNN 레이어에 넣을 수도 있다.\n",
        "본 실습에서는 cell만 만들어서 **SimpleRNNCell, LSTMCell, GRUCell**을 구현해본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMx-9wJ3pMxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f098eb-3425-437e-a5cf-1251cec7ef87"
      },
      "source": [
        "tf.model = tf.keras.Sequential()\n",
        "'''\n",
        "셀을 만들고 RNN 레이어에 추가\n",
        "input_shape = (1,6,5) => 시퀀스 수 (배치), 시퀀스 길이, dim 사이즈\n",
        "'''\n",
        "# SimpleRNNCell을 실행\n",
        "## Argument = 유닛 수, input_shape= 시퀀스 길이, 인풋 차원 수\n",
        "cell = tf.keras.layers.SimpleRNNCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "# cell = tf.keras.layers.LSTMCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "# cell = tf.keras.layers.GRUCell(units=num_classes, input_shape=(sequence_length, input_dim))\n",
        "\n",
        "print(num_classes, sequence_length, input_dim)\n",
        "\n",
        "tf.model.add(tf.keras.layers.RNN(cell=cell, # cell 종류만 바꿔서 실험할 수 있게\n",
        "                                 return_sequences=True))\n",
        "\n",
        "# Fully Connected layer, 활성함수 = softmax\n",
        "tf.model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=num_classes, activation='softmax')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 6 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7rEBC9f462J",
        "colab_type": "text"
      },
      "source": [
        "* tf.keras.Model.compile\n",
        "\n",
        "tf.keras.Model.compile에는 세 개의 중요한 매개변수가 있다:\n",
        "\n",
        "    - optimizer: 훈련 과정을 설정. 'adam'이나 'sgd'와 같이 지정할 수도 있다.\n",
        "    - loss: 최적화 과정에서 최소화될 손실 함수(loss function)를 설정. 평균 제곱 오차(mse)와 categorical_crossentropy, binary_crossentropy 등이 자주 사용된다.\n",
        "    - metrics: 훈련을 모니터링하기 위해 사용된다. 이름이나 tf.keras.metrics 모듈 아래의 호출 가능한 객체이다. 추가적으로 모델의 훈련과 평가를 즉시 실행하려면 run_eagerly=True 매개변수를 전달할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRpKz2UHqd0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 손실함수 = 'categorical_crossentropy, Adam 옵티마이저 사용\n",
        "tf.model.compile(loss='categorical_crossentropy', \n",
        "                 optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
        "                 metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_jRglhb5aYS",
        "colab_type": "text"
      },
      "source": [
        "* tf.keras.Model.fit: 모델 훈련  \n",
        "\n",
        "tf.keras.Model.fit에는 세 개의 중요한 매개변수가 있다:\n",
        "// e.g. model.fit(data, labels, epochs=10, batch_size=32)\n",
        "\n",
        "    - epochs: 훈련은 에포크(epoch)로 구성된다. 한 에포크는 전체 입력 데이터를 한번 순회하는 것이다(작은 배치로 나누어 수행된다).\n",
        "    - batch_size: 넘파이 데이터를 전달하면 모델은 데이터를 작은 배치로 나누고 훈련 과정에서 이 배치를 순회한다. 이 정수 값은 배치의 크기를 지정한다.전체 샘플 개수가 배치 크기로 나누어 떨어지지 않으면 마지막 배치의 크기는 더 작을 수 있다.\n",
        "    - validation_data: 모델의 프로토타입(prototype)을 만들 때는 검증 데이터(validation data)에서 간편하게 성능을 모니터링해야 한다. 입력과 레이블(label)의 튜플을 이 매개변수로 전달하면 에포크가 끝날 때마다 추론 모드(inference mode)에서 전달된 데이터의 손실과 측정 지표를 출력한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6247uhp5auZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "927c9e81-de90-4bb9-d7ac-cea7b47626da"
      },
      "source": [
        "# 훈련\n",
        "tf.model.fit(x_one_hot, y_one_hot, epochs=50) # 에폭 = 50\n",
        "tf.model.summary()\n",
        "\n",
        "predictions = tf.model.predict(x_one_hot)\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(prediction)\n",
        "\n",
        "    # print char using argmax, dict\n",
        "    result_str = [idx2char[c] for c in np.argmax(prediction, axis=1)]\n",
        "    print(\"\\tPrediction str: \", ''.join(result_str))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1 samples\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/sample - loss: 1.7291 - accuracy: 0.1667\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 18ms/sample - loss: 1.3194 - accuracy: 0.3333\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.9917 - accuracy: 0.6667\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.7853 - accuracy: 0.8333\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.6303 - accuracy: 0.8333\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.4985 - accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.3865 - accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.2961 - accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.2270 - accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.1755 - accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.1369 - accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.1070 - accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0829 - accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.0636 - accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 10ms/sample - loss: 0.0486 - accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0374 - accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 9ms/sample - loss: 0.0292 - accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0233 - accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0191 - accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0160 - accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0118 - accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0102 - accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 17ms/sample - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 17ms/sample - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 23ms/sample - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 17ms/sample - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 16ms/sample - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 13ms/sample - loss: 0.0016 - accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 18ms/sample - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 11ms/sample - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 12ms/sample - loss: 0.0013 - accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 14ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 17ms/sample - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 15ms/sample - loss: 0.0011 - accuracy: 1.0000\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "rnn (RNN)                    multiple                  55        \n",
            "_________________________________________________________________\n",
            "time_distributed (TimeDistri multiple                  30        \n",
            "=================================================================\n",
            "Total params: 85\n",
            "Trainable params: 85\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[9.98798847e-01 5.34269551e-04 2.24684729e-04 4.41983633e-04\n",
            "  2.21653707e-07]\n",
            " [1.08620361e-03 9.97940361e-01 1.23226698e-06 1.33599024e-04\n",
            "  8.38521169e-04]\n",
            " [9.99455869e-01 4.79145237e-04 1.07902515e-05 2.67119376e-05\n",
            "  2.73737023e-05]\n",
            " [9.41321196e-04 2.09384343e-05 9.98869359e-01 1.65658217e-04\n",
            "  2.73854789e-06]\n",
            " [5.36645879e-04 3.39400664e-04 4.37477254e-04 9.98685062e-01\n",
            "  1.43127750e-06]\n",
            " [1.09756475e-05 2.24444622e-04 6.91813909e-07 1.67519045e-06\n",
            "  9.99762237e-01]]\n",
            "\tPrediction str:  토마토를먹자\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fEWJjMiqgbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}